{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "cd837b5c-ebd3-4949-9a6a-6c095f974d95",
    "_uuid": "2ab640ac-eb01-4185-b00e-da5672135339",
    "execution": {
     "iopub.execute_input": "2021-05-24T13:31:49.601403Z",
     "iopub.status.busy": "2021-05-24T13:31:49.601081Z",
     "iopub.status.idle": "2021-05-24T13:31:49.609714Z",
     "shell.execute_reply": "2021-05-24T13:31:49.608716Z",
     "shell.execute_reply.started": "2021-05-24T13:31:49.601366Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data_utils\n",
    "import torchvision\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.rpn import AnchorGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "88388ed2-bb56-43c2-ac8f-9aa12b14661a",
    "_uuid": "6716bd63-1af1-407a-8c02-88643d5a8ae3",
    "execution": {
     "iopub.execute_input": "2021-05-24T13:31:49.612285Z",
     "iopub.status.busy": "2021-05-24T13:31:49.611669Z",
     "iopub.status.idle": "2021-05-24T13:31:49.634436Z",
     "shell.execute_reply": "2021-05-24T13:31:49.633623Z",
     "shell.execute_reply.started": "2021-05-24T13:31:49.612242Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class BrailleDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, images, labels):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        images (string): Directory with all the images.\n",
    "        labels (string): Path to a csv file with labels.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(labels, header=None, names=['sheet', 'x1', 'y1', 'x2', 'y2', 'symbol'])\n",
    "    df['symbol'] = df['symbol'].apply(lambda x: x.replace('[\\'', ''))\n",
    "    df['symbol'] = df['symbol'].apply(lambda x: x.replace('\\']', ''))\n",
    "    classes = df.symbol.unique()\n",
    "    self.labels_dict = dict(zip(classes, [x for x in range(45)]))\n",
    "    self.labels = df\n",
    "    self.images = images\n",
    "    \n",
    "  def get_classname(self, value):\n",
    "    for classname, class_number in self.labels_dict.items():\n",
    "        if value == class_number:\n",
    "            return classname\n",
    "    return 'null'\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.labels.sheet.unique())\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    idx += 1\n",
    "    image = cv2.imread(self.images + '/' + str(idx) + '.png', 0)\n",
    "    image = image / 255\n",
    "    image_id = torch.tensor([idx])\n",
    "    label = self.labels[self.labels['sheet'] == idx]\n",
    "    \n",
    "    # Each label consists of fields: sheet number, x1, y1, x2, y2, label.\n",
    "    # Boxes shape: (n_objects, 4).\n",
    "    boxes = np.array(label[['x1', 'y1', 'x2', 'y2']]).reshape((-1, 4))\n",
    "    boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "    \n",
    "    # Labels shape: (n_objects,).\n",
    "    labels = label[['symbol']]\n",
    "    labels = np.array([self.labels_dict.get(labels.iloc[i][0]) for i in range(len(labels))])\n",
    "    labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "    \n",
    "    target = { \"boxes\" : boxes, \"labels\" : labels, \"image_id\" : image_id }\n",
    "\n",
    "    return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "04b56d5c-73bb-43a1-b480-bd266acbf1cc",
    "_uuid": "ec56cc78-2331-48e6-b7ab-e34a72728bc2",
    "execution": {
     "iopub.execute_input": "2021-05-24T13:31:49.639381Z",
     "iopub.status.busy": "2021-05-24T13:31:49.638851Z",
     "iopub.status.idle": "2021-05-24T13:31:50.59818Z",
     "shell.execute_reply": "2021-05-24T13:31:50.597439Z",
     "shell.execute_reply.started": "2021-05-24T13:31:49.639339Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True, box_detections_per_img=500, box_score_thresh=0.4)\n",
    "\n",
    "num_classes = 45\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "844582c6-c4ca-4c96-8af1-f6ea45f2cba5",
    "_uuid": "7311da61-cef3-4e40-a04a-994575d389de",
    "execution": {
     "iopub.execute_input": "2021-05-24T13:31:50.599737Z",
     "iopub.status.busy": "2021-05-24T13:31:50.599385Z",
     "iopub.status.idle": "2021-05-24T13:31:50.606283Z",
     "shell.execute_reply": "2021-05-24T13:31:50.605322Z",
     "shell.execute_reply.started": "2021-05-24T13:31:50.599702Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Describes how to combine tensors of different sizes (due to different number of objects on images).\n",
    "    \"\"\"\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b4e92cb6-de6d-4fbd-826b-e4e66167f420",
    "_uuid": "7ab68c28-7eaf-4f67-975b-7f4fbe7653f9",
    "execution": {
     "iopub.execute_input": "2021-05-24T13:31:50.609972Z",
     "iopub.status.busy": "2021-05-24T13:31:50.609719Z",
     "iopub.status.idle": "2021-05-24T13:31:52.166083Z",
     "shell.execute_reply": "2021-05-24T13:31:52.165113Z",
     "shell.execute_reply.started": "2021-05-24T13:31:50.609947Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_size = 3000\n",
    "test_size = 1000\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "dataset = BrailleDataset('../input/sheets-w-noise/sheets_w_noise', '../input/sheets-labels-w-noise/sheets_labels_w_noise.csv')\n",
    "\n",
    "# Shuffle indices.\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "# Slicing dataset into train and test.\n",
    "dataset_train = torch.utils.data.Subset(dataset, indices[:train_size])\n",
    "dataset_test = torch.utils.data.Subset(dataset, indices[-test_size:])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset_train, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset_test, batch_size=2, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.Adam(params, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T13:31:52.168664Z",
     "iopub.status.busy": "2021-05-24T13:31:52.168397Z",
     "iopub.status.idle": "2021-05-24T13:31:52.175119Z",
     "shell.execute_reply": "2021-05-24T13:31:52.173133Z",
     "shell.execute_reply.started": "2021-05-24T13:31:52.168638Z"
    }
   },
   "outputs": [],
   "source": [
    "print(dataset.labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T13:31:52.176737Z",
     "iopub.status.busy": "2021-05-24T13:31:52.176364Z",
     "iopub.status.idle": "2021-05-24T13:31:52.185522Z",
     "shell.execute_reply": "2021-05-24T13:31:52.184901Z",
     "shell.execute_reply.started": "2021-05-24T13:31:52.176702Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "colors = []\n",
    "for i in range(num_classes):\n",
    "    r = random.randint(0, 255)\n",
    "    g = random.randint(0, 255)\n",
    "    b = random.randint(0, 255)\n",
    "    colors.append((r, g, b))\n",
    "\n",
    "colors_classes = dict(zip([i for i in range(num_classes)], colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T13:31:52.189021Z",
     "iopub.status.busy": "2021-05-24T13:31:52.188504Z",
     "iopub.status.idle": "2021-05-24T13:31:52.198202Z",
     "shell.execute_reply": "2021-05-24T13:31:52.197546Z",
     "shell.execute_reply.started": "2021-05-24T13:31:52.188995Z"
    }
   },
   "outputs": [],
   "source": [
    "def draw_boxes(boxes, labels, scores, image, epoch, image_id):\n",
    "    \"\"\"\n",
    "    Drawing boxes on the original image based on the network predictions. \n",
    "    \"\"\"\n",
    "    model.rpn_score_thresh = 0.8\n",
    "    image = cv2.cvtColor(image.astype('float32'), cv2.COLOR_GRAY2BGR)\n",
    "    for i, box in enumerate(boxes):\n",
    "        class_number = labels[i]\n",
    "        color = colors_classes.get(class_number)\n",
    "        cv2.rectangle(\n",
    "            image,\n",
    "            (int(box[0]), int(box[1])),\n",
    "            (int(box[2]), int(box[3])),\n",
    "            color, 2\n",
    "        )\n",
    "        cv2.putText(image, str(class_number) + ' ' + str(round(scores[i], 2)), (int(box[0]), int(box[1]-5)),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2, \n",
    "                    lineType=cv2.LINE_AA)\n",
    "    ime = PIL.Image.fromarray((image * 255).astype(np.uint8))\n",
    "    ime.save(str(image_id.numpy()[0]) + '_Epoch:' + str(epoch) + '.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T13:31:52.19979Z",
     "iopub.status.busy": "2021-05-24T13:31:52.199415Z",
     "iopub.status.idle": "2021-05-24T13:31:52.212262Z",
     "shell.execute_reply": "2021-05-24T13:31:52.211554Z",
     "shell.execute_reply.started": "2021-05-24T13:31:52.199752Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_iou(boxA, boxB):\n",
    "    \"\"\"\n",
    "    Calculating Intersection Over Union metric.\n",
    "    Args:\n",
    "        boxA (float array): ground truth box,\n",
    "        boxB (float array): predicted box.\n",
    "    \"\"\"\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "\n",
    "    inter_area = abs(max((xB - xA, 0)) * max((yB - yA), 0))\n",
    "    \n",
    "    if inter_area == 0:\n",
    "        return 0\n",
    "    \n",
    "    boxA_area = abs((boxA[2] - boxA[0]) * (boxA[3] - boxA[1]))\n",
    "    boxB_area = abs((boxB[2] - boxB[0]) * (boxB[3] - boxB[1]))\n",
    "\n",
    "    iou = inter_area / float(boxA_area + boxB_area - inter_area)\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T13:31:52.215572Z",
     "iopub.status.busy": "2021-05-24T13:31:52.214803Z",
     "iopub.status.idle": "2021-05-24T13:31:52.223873Z",
     "shell.execute_reply": "2021-05-24T13:31:52.223127Z",
     "shell.execute_reply.started": "2021-05-24T13:31:52.215535Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_metrics(gt_boxes, pred_boxes, target, labels):\n",
    "    \"\"\"\n",
    "    Calculating average Intersection Over Union, average classifiaction accuracy and correct detections percent. \n",
    "    \"\"\"\n",
    "    gts = gt_boxes.tolist()\n",
    "    preds = pred_boxes.tolist()\n",
    "    trgs = target[\"labels\"].numpy().tolist()\n",
    "    lbls = labels.tolist()\n",
    "    \n",
    "    correct_clf = 0.0\n",
    "    correct_det = 0.0\n",
    "    ious = []\n",
    "    \n",
    "    predictions = list(zip(preds, lbls))\n",
    "    targets = list(zip(gts, trgs))\n",
    "    \n",
    "    for (pred_box, l) in predictions:\n",
    "        \n",
    "        for (gt_box, t) in targets:\n",
    "            \n",
    "            iou = get_iou(gt_box, pred_box)\n",
    "            \n",
    "            if iou >= 0.5:\n",
    "                \n",
    "                correct_det += 1\n",
    "                \n",
    "                if l == t:\n",
    "                    correct_clf += 1\n",
    "                    \n",
    "                ious.append(iou)\n",
    "                targets.remove((gt_box, t))\n",
    "                \n",
    "    avg_iou = sum(ious) / len(ious)\n",
    "    clf_accuracy = correct_clf / len(preds)\n",
    "    correct_detections = correct_det / len(gts)\n",
    "    \n",
    "    return avg_iou, clf_accuracy, targets, correct_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T13:31:52.225693Z",
     "iopub.status.busy": "2021-05-24T13:31:52.225251Z",
     "iopub.status.idle": "2021-05-24T13:31:52.238782Z",
     "shell.execute_reply": "2021-05-24T13:31:52.238038Z",
     "shell.execute_reply.started": "2021-05-24T13:31:52.225655Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model, epoch):\n",
    "    \"\"\"\n",
    "    Model evaluation for current epoch (drawing boxes, calculating metrics). \n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    draw = True\n",
    "    ious = []\n",
    "    accuracies = []\n",
    "    undetected = []\n",
    "    detected = []\n",
    "    \n",
    "    for images, targets in test_loader:\n",
    "        \n",
    "        # Draw boxes only for first 3 samples.\n",
    "        if i == 3:\n",
    "            draw = False\n",
    "            \n",
    "        original_images = images    \n",
    "        images = list(torch.from_numpy(image).float().reshape((1, 2000, 1500)).to(device) for image in images)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        original_images = list(original_images)\n",
    "        targets = list(targets)\n",
    "        \n",
    "        for image, output, target in zip(original_images, outputs, targets):\n",
    "            \n",
    "            gt_boxes = target[\"boxes\"].numpy()\n",
    "            pred_boxes = output[\"boxes\"].detach().cpu().numpy()\n",
    "            labels = output[\"labels\"].detach().cpu().numpy()\n",
    "            scores = output[\"scores\"].detach().cpu().numpy()\n",
    "        \n",
    "            if draw:\n",
    "                draw_boxes(pred_boxes, labels, scores, image, epoch, target[\"image_id\"])\n",
    "                \n",
    "            avg_iou, clf_accuracy, undetected_objects, det_obj_percent = get_metrics(gt_boxes, pred_boxes, target, labels)\n",
    "            \n",
    "            ious.append(avg_iou)\n",
    "            accuracies.append(clf_accuracy)\n",
    "            undetected.append(undetected_objects)\n",
    "            detected.append(det_obj_percent)\n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "    # Calculating average metrics throughout the whole epoch.\n",
    "    average_iou = sum(ious) / len(ious)\n",
    "    average_accuracy = sum(accuracies) / len(accuracies)\n",
    "    predicted_boxes = sum(detected) / len(detected)\n",
    "        \n",
    "    return average_iou, average_accuracy, predicted_boxes, undetected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T13:31:52.242016Z",
     "iopub.status.busy": "2021-05-24T13:31:52.240958Z",
     "iopub.status.idle": "2021-05-24T13:31:53.630182Z",
     "shell.execute_reply": "2021-05-24T13:31:53.629144Z",
     "shell.execute_reply.started": "2021-05-24T13:31:52.241977Z"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "do_eval = True\n",
    "\n",
    "all_losses = []\n",
    "clf_losses = []\n",
    "bbox_losses = []\n",
    "avg_ious = []\n",
    "avg_accs = []\n",
    "pred_boxes_num = []\n",
    "undetected_objs = []\n",
    "\n",
    "best_boxes = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "856727fa-d56a-4186-9d82-55ff695d5973",
    "_uuid": "68762520-c705-4fdc-a6a5-ba1193f42ca6",
    "execution": {
     "iopub.execute_input": "2021-05-24T13:31:53.631864Z",
     "iopub.status.busy": "2021-05-24T13:31:53.631504Z",
     "iopub.status.idle": "2021-05-24T14:36:21.959484Z",
     "shell.execute_reply": "2021-05-24T14:36:21.958552Z",
     "shell.execute_reply.started": "2021-05-24T13:31:53.631826Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Training model.\n",
    "\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "        \n",
    "    model.train()\n",
    "    \n",
    "    running_loss_cls = 0.0\n",
    "    running_loss_bbox = 0.0\n",
    "        \n",
    "    start = time.time()\n",
    "        \n",
    "    for images, targets in train_loader:\n",
    "            \n",
    "        images = list(torch.from_numpy(image).float().reshape((1, 2000, 1500)).to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            \n",
    "        loss_dict = model(images, targets)\n",
    "            \n",
    "        loss_classifier = loss_dict[\"loss_classifier\"]\n",
    "        loss_box_reg = loss_dict[\"loss_box_reg\"]      \n",
    "\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        loss_value = losses.item()\n",
    "        running_loss_cls += loss_classifier\n",
    "        running_loss_bbox += loss_box_reg                                                        \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "    t = time.time() - start\n",
    "        \n",
    "    all_losses.append(loss_value)\n",
    "    clf_losses.append(running_loss_cls / train_size)\n",
    "    bbox_losses.append(running_loss_bbox / train_size)\n",
    "        \n",
    "    print('Epoch: {}, Loss_classifier: {:.4f}, Loss_box_reg: {:.4f}, Train time: {:.4f} min'.format(epoch, running_loss_cls / train_size, running_loss_bbox / train_size, t / 60))\n",
    "        \n",
    "    if do_eval:\n",
    "        model.eval()\n",
    "        average_iou, average_accuracy, predicted_boxes, undetected = evaluate(model, epoch)\n",
    "        avg_ious.append(average_iou)\n",
    "        avg_accs.append(average_accuracy)\n",
    "        pred_boxes_num.append(predicted_boxes)\n",
    "        undetected_objs.append(undetected)\n",
    "        print('Epoch: {}, Average IoU: {:.4f}, Average accuracy: {:.4f}, Average predicted boxes percent: {:.4f}'.format(epoch, average_iou, average_accuracy, predicted_boxes))\n",
    "\n",
    "        if best_boxes < predicted_boxes:\n",
    "            best_boxes = predicted_boxes\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T14:36:21.966206Z",
     "iopub.status.busy": "2021-05-24T14:36:21.964027Z",
     "iopub.status.idle": "2021-05-24T14:36:22.581204Z",
     "shell.execute_reply": "2021-05-24T14:36:22.58013Z",
     "shell.execute_reply.started": "2021-05-24T14:36:21.966162Z"
    }
   },
   "outputs": [],
   "source": [
    "# Saving best model weights.\n",
    "\n",
    "PATH = \"state_dict_model.pt\"\n",
    "torch.save(best_model_wts, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = { 'а': 1, 'б': 2, 'ц': 3, 'д': 4, 'е': 5, 'ф': 6, 'г': 7, 'х': 8, 'и': 9, 'ж': 0 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_text(pred_boxes, labels, n):\n",
    "    \"\"\"\n",
    "    Translating text in Braille to text in Russian based on network predictions.\n",
    "    Args:\n",
    "        pred_boxes (float array): predicted coordinates for letters,\n",
    "        labels (int array): predicted letters,\n",
    "        n (int): image serial number.\n",
    "    \"\"\"\n",
    "    text = \"\"\n",
    "    pred_boxes = pred_boxes.tolist()\n",
    "    labels = labels.tolist()\n",
    "    \n",
    "    fname = str(n) + '.txt'\n",
    "    f = open(fname, \"w\")\n",
    "    \n",
    "    is_number = False\n",
    "    is_capital = False\n",
    "    \n",
    "    # Networks returns predictions in random order so we need to\n",
    "    # sort boxes and group them (one group corresponds to one line of text).\n",
    "    \n",
    "    # Sorting predicted boxes by y1 (each box consists of [x1, y1, x2, y2]).\n",
    "    sorted_by_y = sorted(list(zip(pred_boxes, labels)), key = lambda x: x[0][1])\n",
    "    \n",
    "    lines = []\n",
    "    line = []\n",
    "    is_new_line = False\n",
    "    prev_box_y1 = sorted_by_y[0][0][1]\n",
    "    \n",
    "    for sym in sorted_by_y:\n",
    "        \n",
    "        curr_box_y1 = sym[0][1]\n",
    "        \n",
    "        # If distance between two symbols (vertically) is greater than approximate \n",
    "        # symbol height, this means we have a new line.\n",
    "        if abs(prev_box_y1 - curr_box_y1) > 50:\n",
    "            is_new_line = True\n",
    "            \n",
    "        prev_box_y1 = curr_box_y1\n",
    "        \n",
    "        if is_new_line and len(line) > 0:\n",
    "            lines.append(line)\n",
    "            line = []\n",
    "            is_new_line = False\n",
    "            \n",
    "        line.append(sym)\n",
    "        \n",
    "    # All symbols have been grouped into \"lines\".\n",
    "    lines.append(line)\n",
    "        \n",
    "    for l in lines:\n",
    "        \n",
    "        # Sorting symbols in each line by x1 to recreate letters order.\n",
    "        sorted_by_x = sorted(l, key = lambda x: x[0][0])\n",
    "        \n",
    "        prev_box_x1 = sorted_by_x[0][0][0]\n",
    "        \n",
    "        # Putting the text together.\n",
    "        for box, label in sorted_by_x:\n",
    "            \n",
    "            curr_box_x1 = box[0]\n",
    "            curr_box_x2 = box[2]\n",
    "        \n",
    "            symbol = dataset.get_classname(label)\n",
    "            \n",
    "            if symbol == 'цифровой символ':\n",
    "                is_number = True\n",
    "            \n",
    "            if symbol == 'знак заглавной буквы':\n",
    "                is_capital = True\n",
    "        \n",
    "            if abs(prev_box_x1 - curr_box_x1) > 80: \n",
    "                if is_number == True:\n",
    "                    is_number = False\n",
    "                text = text + \" \"\n",
    "            \n",
    "            if is_capital and symbol != 'знак заглавной буквы':\n",
    "                symbol = symbol.upper()\n",
    "            elif is_number and symbol != 'цифровой символ':\n",
    "                symbol = str(numbers.get(symbol))\n",
    "            \n",
    "            is_capital = False\n",
    "        \n",
    "            if symbol != 'цифровой символ' and symbol != 'знак заглавной буквы':\n",
    "                text = text + symbol\n",
    "        \n",
    "            prev_box_x1 = curr_box_x1\n",
    "            \n",
    "        text += '\\n'\n",
    "    \n",
    "    f.write(text)\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
