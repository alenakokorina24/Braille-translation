{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import imgaug.augmenters as iaa\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(350, 64, 40, 1)\n"
     ]
    }
   ],
   "source": [
    "# Reading images of characters without background. \n",
    "\n",
    "path = '/home/alena/jupyter/jupyter/Optical-Braille-Recognition-System/dataset/chars_wo_background'\n",
    "\n",
    "n = 0\n",
    "X = []\n",
    "\n",
    "for root, dirs, files in os.walk(path):\n",
    "    files = [file[:-4] for file in files]\n",
    "    files = sorted(map(int, files))\n",
    "    for filename in files:\n",
    "        filename = str(filename) + '.jpg'\n",
    "        example = cv2.resize(cv2.imread(path + '/' + filename, 0), (40, 64))\n",
    "        X = np.append(X, example)\n",
    "        \n",
    "        n += 1\n",
    "        \n",
    "X = X.reshape(n, 64, 40, 1).astype(np.uint8)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading \"noise\" characters (decimal numbers).\n",
    "\n",
    "path = '/home/alena/jupyter/jupyter/Optical-Braille-Recognition-System/dataset/noise'\n",
    "\n",
    "ni = 0\n",
    "noise = []\n",
    "\n",
    "for root, dirs, files in os.walk(path):\n",
    "    files = [file[:-4] for file in files]\n",
    "    files = sorted(map(int, files))\n",
    "    for filename in files:\n",
    "        filename = str(filename) + '.jpg'\n",
    "        example = cv2.resize(cv2.imread(path + '/' + filename, 0), (40, 64))\n",
    "        noise = np.append(noise, example)\n",
    "        ni += 1\n",
    "        \n",
    "noise = noise.reshape(ni, 64, 40, 1).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_excel('/home/alena/jupyter/jupyter/Optical-Braille-Recognition-System/dataset/braille_characters_labels_full.xlsx', header=None)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Width and height of each sheet.\n",
    "w, h = 1500, 2000\n",
    "\n",
    "# Width and height of each symbol.\n",
    "H_SYM = 64-4\n",
    "W_SYM = 40-4\n",
    "\n",
    "#sheet[0:48,0:30] = example\n",
    "#plt.imshow(sheet, cmap='gray')\n",
    "#plt.show()\n",
    "#cv2.imwrite('krya.png', sheet)\n",
    "\n",
    "# Each page contains 5 to 20 lines.\n",
    "N_EXAMPLES = 201\n",
    "MIN_LINES = 5\n",
    "MAX_LINES = 20\n",
    "\n",
    "# Distances between side characters and page edges.\n",
    "H_PAGE_INDENT = 70\n",
    "W_PAGE_INDENT = 80\n",
    "\n",
    "# Distance between characters inside the word.\n",
    "SYM_INDENT = 10\n",
    "\n",
    "# Distances between words vertically and horizontally. \n",
    "H_WORD_INDENT = 30\n",
    "W_WORD_INDENT = 50\n",
    "\n",
    "# Each line contains 3 to 6 words or 0 words with probability of 5%.\n",
    "# Each word consists of:\n",
    "# 1-2 letters - 40%, \n",
    "# 3-7 letters - 50%,\n",
    "# 8-11 letters - 10%.\n",
    "\n",
    "# Each symbol has random offset in the range of 0 to 3 vertically and horizontally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-115f5271c682>:55: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  sheets_labels = np.array([i, x, y, x + W_SYM, y + H_SYM, labels[index]])\n",
      "<ipython-input-7-115f5271c682>:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  sheets_labels = np.vstack((sheets_labels, np.array([i, x, y, x + W_SYM, y + H_SYM, labels[index]])))\n"
     ]
    }
   ],
   "source": [
    "sheets_labels = np.array([])\n",
    "\n",
    "for i in range(N_EXAMPLES):\n",
    "    \n",
    "    sheet = np.full((h, w, 1), 255)\n",
    "    x_pointer = W_PAGE_INDENT\n",
    "    y_pointer = H_PAGE_INDENT\n",
    "    \n",
    "    n_lines = random.randint(MIN_LINES, MAX_LINES)\n",
    "    \n",
    "    for j in range(n_lines):\n",
    "        \n",
    "        if random.random() < 0.05:\n",
    "            continue\n",
    "        \n",
    "        n_words = random.randint(3, 6)\n",
    "        \n",
    "        for k in range(n_words):\n",
    "            \n",
    "            r = random.random()\n",
    "            if r < 0.1:\n",
    "                n_letters = random.randint(8, 11)\n",
    "            elif r < 0.4:\n",
    "                n_letters = random.randint(1, 2)\n",
    "            else:\n",
    "                n_letters = random.randint(3, 7)\n",
    "            \n",
    "            # If the word is too long to fit in line, skip it.\n",
    "            if x_pointer < w - n_letters * (W_SYM + SYM_INDENT) - W_PAGE_INDENT - 2:\n",
    "                for q in range(n_letters):\n",
    "                \n",
    "                    x_offset = random.randint(-2, 2)\n",
    "                    y_offset = random.randint(-2, 2)\n",
    "                \n",
    "                    x = x_pointer + x_offset\n",
    "                    y = y_pointer + y_offset\n",
    "                    \n",
    "                    if random.random() < 0.02:\n",
    "                        char = noise[random.randint(0, 8)]\n",
    "                    else:\n",
    "                        index = random.randint(0, 349)\n",
    "                            \n",
    "                        char = X[index]\n",
    "                    \n",
    "                        if i == 0 and q == 0:\n",
    "                            sheets_labels = np.array([i, x, y, x + W_SYM, y + H_SYM, labels[index]])\n",
    "                        else:\n",
    "                            sheets_labels = np.vstack((sheets_labels, np.array([i, x, y, x + W_SYM, y + H_SYM, labels[index]])))\n",
    "                        \n",
    "                        dots = char[char < 210].flatten()\n",
    "                        avg = np.sum(dots) / len(dots)\n",
    "                        if avg > 150:\n",
    "                            char[char < 210] = char[char < 210] - 30\n",
    "                        elif avg < 140:\n",
    "                            char[char < 210] = char[char < 210] + 30\n",
    "                            \n",
    "                    #print(y, y+H_SYM, x, x+W_SYM, char.shape)\n",
    "                    \n",
    "                    # Applying minor rotation.\n",
    "                    p = random.randint(0, 5)\n",
    "                    aug = iaa.Affine(rotate=(-p, p))\n",
    "                    char = aug(image=char)\n",
    "                    char = char[2:H_SYM+2, 2:W_SYM+2]\n",
    "                    \n",
    "                    sheet[y:y+H_SYM, x:x+W_SYM] = char\n",
    "                    x_pointer += (W_SYM + SYM_INDENT)\n",
    "                \n",
    "                x_pointer += W_WORD_INDENT\n",
    "                \n",
    "        x_pointer = W_PAGE_INDENT\n",
    "        y_pointer += (H_SYM + H_WORD_INDENT)     \n",
    "        \n",
    "    flat = sheet.flatten()    \n",
    "    white = np.where(np.logical_and(flat <= 255, flat >= 210)) \n",
    "    np.put(flat, white, 170)\n",
    "    sheet = flat.reshape((2000, 1500, 1)).astype(np.uint8)\n",
    "    \n",
    "    # Applying some gaussian noise.\n",
    "    p = random.uniform(0.05, 0.1)\n",
    "    aug = iaa.AdditiveGaussianNoise(scale=(0, p*255))\n",
    "    sheet = aug(image=sheet)\n",
    "    \n",
    "    cv2.imwrite('/home/alena/jupyter/jupyter/Optical-Braille-Recognition-System/dataset/dot/' + str(i) + '.png', sheet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing labels.\n",
    "\n",
    "with open('/home/alena/jupyter/jupyter/Optical-Braille-Recognition-System/dataset/dots_labels_1.csv', 'w', newline='') as file:\n",
    "    mywriter = csv.writer(file, delimiter=',')\n",
    "    mywriter.writerows(sheets_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
